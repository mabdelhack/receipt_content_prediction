# -*- coding: utf-8 -*-
"""receipt_prediction_abdelhack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17k9IKTFKXBD1Pb38S2eQzAEUre27dKpr
"""

cd ~

!wget https://storage.googleapis.com/hackaitn2019-datasets/computer-vision-expensya.zip

!unzip computer-vision-expensya.zip

cd Computer\ Vision\ -\ Expensya

!unzip expensya_train_test_data.zip

cd tosend\ 2

!unzip test.zip

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook

from __future__ import division, print_function
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import tensorflow as tf
import pandas as pd

plt.rcParams.update({'figure.figsize': (5.0, 4.0), 'lines.linewidth': 2.0})

pwd

!mkdir train_divided

source_folder = './train'

labDF = pd.read_csv('../train_labels.csv')

!mkdir train_divided/fuel
!mkdir train_divided/parking
!mkdir train_divided/restaurant
!mkdir train_divided/transport

from shutil import copyfile


for index, row in labDF.iterrows():
  imgID = row.img_id
  if row.fuel == 1:
    copyfile('./train/' + str(imgID) + '.png', './train_divided/fuel/' + str(imgID) + '.png')
  elif row.parking == 1:
    copyfile('./train/' + str(imgID) + '.png', './train_divided/parking/' + str(imgID) + '.png')
  elif row.restaurant == 1:
    copyfile('./train/' + str(imgID) + '.png', './train_divided/restaurant/' + str(imgID) + '.png')
  elif row.transport == 1:
    copyfile('./train/' + str(imgID) + '.png', './train_divided/transport/' + str(imgID) + '.png')

input_layer = tf.keras.layers.Input(shape=(224,224,3), name='input_img')
conv1_1 = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_1_1')(input_layer)
conv1_2 = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_1_2')(conv1_1)
conv1_3 = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_1_3')(conv1_2)
pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='valid', name='pool_1')(conv1_3)
# bn1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, name='bn_1')(pool1)
conv2_1 = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_2_1')(pool1)
conv2_2 = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_2_2')(conv2_1)
conv2_3 = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_2_3')(conv2_2)
pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='valid', name='pool_2')(conv2_3)
conv3_1 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_3_1')(pool2)
conv3_2 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_3_2')(conv3_1)
conv3_3 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_3_3')(conv3_2)
pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='valid', name='pool_3')(conv3_3)
conv4_1 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_4_1')(pool3)
conv4_2 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_4_2')(conv4_1)
conv4_3 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_4_3')(conv4_2)
pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='valid', name='pool_4')(conv4_3)
conv5_1 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_5_1')(pool4)
conv5_2 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_5_2')(conv5_1)
conv5_3 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu', name='conv_5_3')(conv5_2)
pool5 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='valid', name='pool_5')(conv5_3)
bn1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, name='bn_2')(pool5)
flatten_1 = tf.keras.layers.Flatten(name='flat_1')(bn1)
do1 = tf.keras.layers.Dropout(0.2)(flatten_1)
fc4 = tf.keras.layers.Dense(4096, activation='relu', name='fc_4')(do1)
fc5 = tf.keras.layers.Dense(2048, activation='relu', name='fc_5')(fc4)
out = tf.keras.layers.Dense(4, activation='softmax', name='out')(fc5)

model = tf.keras.models.Model(input_layer, 
                              out)
# print network structure
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(lr=1e-4),
              metrics=['acc'])
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                                                rotation_range=180,
                                                                width_shift_range=0.3,
                                                                height_shift_range=0.3,
                                                                shear_range=30.0,
                                                                zoom_range=1.5,
                                                                fill_mode='nearest',
                                                                horizontal_flip=True,
                                                                vertical_flip=True
                                                               )
train_generator = train_datagen.flow_from_directory(
        './train_divided/',  # This is the source directory for training images
        target_size=(224, 224),  # All images will be resized to 20x20
        color_mode='rgb',
        batch_size=64,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='categorical')

history = model.fit_generator(
      train_generator,
      steps_per_epoch=1000,  # 2000 images = batch_size * steps
      epochs=2)

history = model.fit_generator(
      train_generator,
      steps_per_epoch=1000,  # 2000 images = batch_size * steps
      epochs=5,
      initial_epoch=2)

model.save('2_epochs.h5')

model.save('5_epochs.h5')

history = model.fit_generator(
      train_generator,
      steps_per_epoch=1000,  # 2000 images = batch_size * steps
      epochs=10,
      initial_epoch=5)

model.save('10_epochs.h5')

import skimage.io
from glob import glob
import os
from skimage.transform import resize

sample_data = pd.read_csv("../sample_sub.csv")
output_data = sample_data
print(sample_data.shape)

test_folder = './test/'
prediction_targets = 4
# filelist = glob(os.path.join(test_folder , '*.png'))
test_fields = sample_data.shape[0]
pred_probs = np.zeros((test_fields, prediction_targets))
#     print(field_filelist)
for img_idx, img in sample_data.iterrows():
    map_array = skimage.io.imread(os.path.join(test_folder, str(int(img.img_id)) + '.png'))
    map_array = map_array/255.0
    map_array = resize(map_array, (224,224),
                       anti_aliasing=True)
    map_array = np.expand_dims(map_array, axis=0)
    predictions = model.predict(map_array)
#     print(predictions[0])
#     pred_probs[img_idx, :] = predictions
    sample_data.loc[img_idx,'fuel'] = predictions[0][0]
    sample_data.loc[img_idx,'parking']  = predictions[0][1]
    sample_data.loc[img_idx,'restaurant']  = predictions[0][2]
    sample_data.loc[img_idx,'transport']  = predictions[0][3]
    
#     print(predictions)
#     break
# pred_probs_mean = pred_probs.mean(axis=0)
# print(pred_probs_mean)

sample_data.to_csv("./results_10epoch_noaugmentation.csv", index=False)